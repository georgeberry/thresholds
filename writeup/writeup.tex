\documentclass[a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}

\usepackage[table]{xcolor}
\usepackage{csquotes}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{verbatim}
\usepackage{afterpage}
\usepackage{placeins}
\usepackage{bbm}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}

\newcommand{\notimplies}{%
  \mathrel{{\ooalign{\hidewidth$\not\phantom{=}$\hidewidth\cr$\implies$}}}}

% Allow commenting
\newif\ifdraft\draftfalse
%\usepackage{xcolor}
\newcommand\ccnote[1]{\ifdraft{\color{olive} [CC: #1]}\fi}
\newcommand\gbnote[1]{\ifdraft{\color{purple} [GB: #1]}\fi}
\newcommand\mmnote[1]{\ifdraft{\color{orange} [MM: #1]}\fi}


\newtheorem{definition}{Definition}
\newtheorem{condition}{Condition}
\newtheorem{assn}{Assumption}
\newtheorem{theorem}{Theorem}

\usepackage[backend=biber,style=authoryear]{biblatex}
\addbibresource{thresholdbib.bib}

\title{Correctly Measuring Social Contagion}
\author{George Berry and Christopher J. Cameron}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}
We prove that activation thresholds are impossible to correctly measure for some nodes in virtually all social contagion processes, even when each step of the process is observed. We show that the mis-measurement always produces an overestimate of a node's true threshold. This implies that statistical models that estimate the effect of peers on behavior produce biased estimates of social influence, even in regression and nonparametric models that do not explicitly incorporate thresholds. We use simulation to determine the severity of incorrect measurement, and find that mis-measurement is a function of the threshold distribution and network structure. We propose modeling activation thresholds as a function of node-level covariates, and demonstrate that this approach can allow reasonable---but not unbiased---estimation of true thresholds and threshold distributions, using only the correctly measured subset. Our estimation procedure reduces bias by more than 80\% compared to existing approaches.
\end{abstract}

\section{Introduction}

\begin{comment}
TODO:
1. make clearer distinction between states-of-world and the parts the researcher observes
2. proof read
3. graph of error in non-threshold regression model
4. prediction at k correct baseline
\end{comment}

Threshold approaches have long been central to understanding the diffusion of innovations, information cascades, and behavioral change in networks \parencite{Rogers1962, Granovetter1978, Valente1996, Kempe2003, Macy1990, Watts2002}. When individuals in a social network face uncertain adoption decisions or when adoption decisions exhibit strategic complimentarities, the behavior of network neighbors can play a crucial role in decision making. Threshold approaches provide a useful abstraction to model these types of interdependent decisions: nodes require a certain level of social reinforcement from peers before adopting.

Thresholds have been widely adopted as a technique to model social contagion \parencite{Centola2007, Granovetter1978, Watts2002, Greve1995a, Macy1991c}. Additionally, the concept of a threshold can be seen in classical studies of diffusion \parencite{Coleman1957, Rogers1962, Burt2016, Granovetter1986}, in the utility functions of contemporary studies of peer influence \parencite{}, in models of influence maximization \parencite{}, in empirical studies of adoption behavior \parencite{Valente1995, Valente1996, Ludemann1999a, Romero2011}, and in models of social influence more generally \parencite{christakis-fowler, Marsden, Friedkin}. When we posit that the utility from peer adoptions can cause a focal actor to engage in a new behavior, we implicitly talk about adoption thresholds. Intuitively, there is \emph{some} critical number of peer adoptions that actually induces the switch.

In this paper, we lay out a fundamental problem with threshold approaches: not all thresholds can be empirically measured in networked social contagion processes. This creates a type of missing data: nodes are ``missing'' because we can only place their adoption threshold in an interval---and the theoretical maximum size of such intervals is the node's degree. Past research has taken the maximum of this interval for all nodes in the graph, leading to \emph{only} upwardly biased estimates of node thresholds. This causes problems even in models where the concept of a threshold is not employed explicitly. For instance, a utility-based model of adoption that includes the number of active neighbors as a predictor for adoption status will underestimate the true marginal utility of peer adoption. This happens because the variable is biased upward in the case where a node is recorded as active.

The inability to correctly measure node thresholds does not result from a failure to observe all stages of a contagion process: we cannot simply get ``more data'' about a given process and correctly measure node thresholds. Rather, the failure of measurability that we discover results from the logical combination of graphs, node thresholds, and node update orderings. We prove that a wide class of contagion processes are not threshold measurable, and these proofs are remarkably simple. In addition, we provide examples of contagion processes that \emph{are} threshold measurable. While not exhaustive, the complexity of these examples suggests that few processes are measurable.

Specifically, the failure of measurability applies to all social contagion processes where the researcher both (i) cannot observe a node's private threshold satisfaction status and (ii-a) does not know a node's delay before activating or (ii-b) asserts that activation is instantaneous. Since empirical studies of social contagion---even experimental ones---often do not know this private information, we conclude that the upward bias we identify in this paper affects studies of social contagion quite generally.

Although not all node thresholds can be correctly measured in social contagion processes, we demonstrate that modeling adoption thresholds as a function of node-level observables can substantially reduce the bias induced by using the ``number of neighbors at activation time'' rule for measuring thresholds \parencite{Valente1996}. Among studies that have explicitly applied thresholds to empirical data \parencite{Valente1995, Valente1996, Ludemann1999a, Romero2011}, none have recognized the measurability problem that we highlight in this paper. To our knowledge, estimating node thresholds as a function of node-level characteristics has not been attempted.

The rest of this article is organized as follows: In section \ref{sec:intuition}, we provide an intuitive statement of the measurability problem. In section \ref{sec:proof}, we formally define a contagion process and prove our main result that thresholds cannot be correctly measured in most social contagion processes. In section \ref{sec:bias}, we provide a brief proof that if we cannot correctly measure adoption thresholds, existing models systematically underestimate the magnitude of social influence and peer effects. In section \ref{sec:simulation}, we demonstrate through simulation the typical magnitude of the upward bias in threshold measurement, and provide an example of how this bias can be reduce through prediction conditional on node-level covariates. We find that by using only the correctly measured subset of nodes (often around 10\% of the data), we obtain a much better estimate of true node thresholds.

This paper is motivated by a desire to directly investigate empirical social contagion processes using existing theory. For instance, \cite{Centola2007} propose the theory of \emph{complex contagion}, where individuals require multiple instances of social reinforcement before adopting. If researchers would like to assess the level of ``complexity'' of an empirical social contagion, existing approaches produce systematically incorrect results. One can only undertake such an analysis with the techniques developed in this paper.

\section{An Intuitive Example} \label{sec:intuition}

To see the problem intuitively, consider the following hypothetical laboratory experiment: we wish to see how many alter adoptions are required for an individual to commit to purchasing a product. We show her a computer screen indicating that zero friends have adopted and ask her whether she would like to purchase the product. We repeat this process for one, two, and three friends. After the second friend activation, she indicates that she would purchase the product. Since we know she did not adopt with zero or one alters active, but did adopt when two alters were active, we correctly measure her adoption threshold as two.

Consider the case of a lazy research assistant, who forgets to check with ego after the first and second alters have adopted. The assistant checks with ego with zero active friends, and again when she has three active friends, where ego indicates that she would adopt. In this case, we do not have a measurement of ego's activation status with 1 and 2 active alters. Therefore, the most precise statement we can make based on this data is that her true threshold lies in the half-open interval $(0, 3]$.

If we do not have a record of ego's activation status after some alter activations, we can fail to correctly measure ego's adoption threshold. This happens in instances where nodes check their alter status at intervals, giving multiple friends time to adopt. For instance, if an individual checks her friends' statuses at $t = 1$ and $t = 3$, and 5 friends adopt at time $t = 2$, we have no way of ascertaining the minimum exposure level that \emph{would have induced} her to adopt, we only obtain an interval between 1 and 5.

This discussion also suggests a way to ensure correct measurement of activation thresholds: systematically randomize an individual's ego network. Such studies have been conducted in online environments \parencite{Aral2008, Bakshy2011}, and offer the best chance of avoiding the problems we detail in this paper.

\section{Threshold Measurability}

In this section, we prove that contagion processes relevant to social scientists are not threshold measurable. We start with an observation: researchers generally do not have control over the network structure or node update order.

We assume that these three elements are out of the researcher's control. If the researcher has control over threshold assignment, there is no need to estimate the threshold distribution. If the researcher can design the network structure \parencite{centola} or enforce that nodes update in a certain order \parencite{tsvetkova}, then thresholds may be correctly measured at a higher rate. However, in the vast majority of studies---including all observational studies and some experimental studies---these factors are not controlled by the researcher. The only research design that we're aware of that fully alleviates the problems discussed in this section is a randomized experiment with control over the information transmitted to ego (e.g. \cite{bakshy}).

\subsection{Preliminaries}

A contagion process happens on a network $G = (V, E)$ where $V$ represents the nodes and $E$ represents the edges. Each node $i \in V$ has threshold $h_i \in \mathbb{R}$. $e_i$ is a node's \emph{exposure}, or its number of active neighbors. Each $i \in V$ has a public \emph{activation status} $a_i \in \{0, 1\}$, where 1 indicates that $i$ is activated By ``public'', we mean that $i$'s neighbors can observe this activation. Each $i$ also has a private \emph{threshold satisfaction} status $s_i \in \{0, 1\}$, by which we mean that $i$'s exposure $e_i$ may be greater than its threshold $h_i$, but $i$ may not yet be publicly active due to an activation delay $\delta_i$.

These elements give the basic contours of a contagion process, but there are no dynamics. We need a method for, at some time $t$, a node to update and learn its own statuses by comparing its exposure $e_i^t$ with its threshold $h_i^t$. Let $U$ be an update ordering of the form $(\{i\}, \{j, k\}, ...)$. This ordering indicates that $i$ updates at time 1, then $j$ and $k$ update simultaneously at time 2. Without loss of generality, assume time is discrete\footnote{Any continuous time process can be transformed to discrete time by putting the nodes in order by update time and assigning the first node to time 1, the second to time 2, and so forth. We allow two nodes to update at the same time, synchronous or asynchronous updating makes no difference for our argument.}. Then we add dynamics by assuming that nodes update according to $U$. In particular, a node $i$ checks whether $h^t_i > e^t_i$, and if yes, sets $s^t_i = 1$, and then schedules public activation for time $a^{t+\delta_i}_i = 1$\footnote{If more than one node updates at a given time $t$, we assume they update according to the state of the contagion at the beginning of the time step. E.g. if $i$ and $j$ are neighbors and both update at $t$, we assume that they don't know about each other's change in activation status in the same period.}.

Note that we have refrained from making assumptions about the graph structure, the threshold distribution, the distribution of update orderings, and so forth. We introduce a couple of additional assumptions below, but generally refrain from making distributional assumptions.

\subsection{Who knows what}

There are a couple of important things to note about who knows what in this process. We rely on nodes to check their own states according to the update ordering $U$. However, because of the potential complication of activation delays, a node may know that its threshold has been satisfied before it takes the step of publicly activating. We can easily imagine both types of processes, and so we discuss both in the interest of generality.

In the subsequent sections, it will become important to discuss precisely what information the researcher has access to. When observing a contagion process, we assume that the researcher observes a contagion process and has access to some set of data generated by the process. Based on that data, the researcher wishes to infer node thresholds.

In this context, let's develop notation for two important concepts: 1) the \emph{full record} of the contagion process; 2) the \emph{observable record} of the contagion process. The full record contains all information about the graph and nodes, along with all information about each step of the process. Think of the full record as the ``truth'' that we are trying to infer. The observable record is a graph plus a sequence of states that the researcher can actually observe in practice.

Given a fixed graph $G$, vector of thresholds $H$, update ordering $U$, and vector of activation delays $\Delta$, define the set of \emph{states of the world} $\Omega$. Each $\omega \in \Omega$ completely represents the full record at time $t$. At $t$, call $E^t$ the vector of exposure, $S^t$ the vector of threshold satisfaction statuses, and $A^t$ the vector of public activation statuses. Then we have each $\omega$ given by the tuple $(t, G, H, U, \Delta, E^t, S^t, A^t)$. We call $\Omega$ the \emph{full record}, and $\omega$ the \emph{full record at time $t$}.

Now assume that a researcher observes a contagion process in the wild. The researcher records snapshots of the full record that contain only partial information. Call the \emph{observable record} $\Omega_R$, and it contains the states of the world that the contagion process achieved, which were also measured by the researcher. Elements $\omega_R$ do not contain all of the information in $\omega$, but have elements hidden according to the particulars of the data-gathering process. For instance, perhaps a reseracher cannot observe a node's threshold satsfaction status as distinct from public activation, so $S^t$ would be hidden in $\omega_R$.

The core argument of our paper can be framed as follows: ``nature'' reveals certain states of the world to the researcher, $\Omega_R$. The researcher must infer $H$ from $\Omega_R$. When elements of $\Omega$ are hidden from $\Omega_R$, the task of inferring the full vector $H$ from $\Omega_R$ becomes impossible.

\subsection{Assumptions}

We make some assumptions to set up the formal proof of our main result. These assumptions are sensible scope conditions that are necessary to make our argument accord with the types of contagion process encountered in the social world.

\begin{assn} \label{assn:immutability}
\textbf{Non-intervention}: The researcher can not change $G$ or $H$ under any circumstances
\end{assn}

\begin{assn} \label{assn:ignorance}
\textbf{Ignorance}: The researcher does not in advance know any $h_i \in H$
\end{assn}

\begin{assn} \label{assn:perfect_obs}
\textbf{Granularity}: $\Omega_R$ contains all realized $\omega_R$
\end{assn}

\noindent
Assumption \ref{assn:perfect_obs} means that the researcher observes every state that the contagion process achieves. This assumption means that there is not a finer-grained sampling of the contagion process that can be employed: we have all the data that exists, subject to the constrain that some elements such as the vector of true thresholds $H$ are hidden from the full record $\Omega$. In practice we often receive samples of the underlying contagion process, but by assuming that we cannot gather more data, our argument applies to the contagion process itself and not the sampling method.

We also make two technical assumptions that make the proof below more straightforward:

\begin{assn} \label{assn:saturation}
\textbf{Saturation}: All nodes in $V$ activate eventually
\end{assn}

\begin{assn} \label{assn:consistency}
\textbf{Consistency}: $G, U, H, and \Delta$ are consistent with Assumption \ref{assn:saturation}
\end{assn}

\noindent
We make these assumptions to simplify the analysis without loss of generality. Since we study a contagion process, assuming that all nodes activate eventually is a natural simplification that makes the proof easier. This implies that nodes do not activate ``by magic'', and so the graph, update ordering, threshold assignment, and activation delays must be consistent with the contagion process actually diffusing.

Practically speaking, however, the contagion process does not have to saturate for our result to apply. Simply take the subgraph of eventually activated nodes, then Assumption \ref{assn:saturation} and Assumption \ref{assn:consistency} apply and our results hold.

\subsection{Definitions}

\begin{definition} \label{def:knowledge}
When the researcher systematically cannot observe an element of $\omega_R$ we say that element is \textbf{hidden}
\end{definition}

\noindent
For instance, $H$ is always hidden, and we write $\omega = (t, E, S, A)$ to denote this. $E$ and $A$ are never hidden, with $S$ varying depending on the particulars of the contagion process. We treat hidden elements as if they did not exist for the purpose of inferring $H$.

\begin{definition} \label{def:measured}
A threshold $h_i$ is \textbf{correctly measured} when either:
\begin{enumerate}
\item If $S$ is not hidden: for some $t, t' \in U_i$, $t' > t$, we have $e_i^{t'} - e_i^t = 1$ and $s_i^{t'} = 1$ while $s_i^t = 0$
\item If $S$ is hidden but $A$ is not hidden: for some $t, t' \in U_i$, $t' > t$, we have $e_i^{t'} - e_i^t = 1$ and $a_i^{t'} = 1$ while $a_i^t = 0$
\end{enumerate}
\end{definition}

\noindent
Restricting ourselves to $t, t' \in U_i$ means that we do not have any information $i$ does not have. Intuitively, we can not check $i$'s status before $i$ does---if we could, it would imply that we knew $h_i$ already. If we have access to $i$'s private information $s_i$, then Definition \ref{def:measured}.1 applies, otherwise Definition \ref{def:measured}.2 applies.

Stated another way, given $\Omega_R$, we correctly measure $i$'s threshold if, for some $\omega_R, \omega_R' \in \Omega_R$, $e_i^{t'} - e_i^t = 1$ and either $s_i^{t'} - s_i^t = 1$ or $a_i^{t'} - a_i^t = 1$. Call the correctly measured subset $C$. Definition \ref{def:measured} can be applied to straightforwardly to empirical data.

Stating correct measurement for a single $i$ allows us to formulate a condition for the all nodes in the contagion process.

\begin{definition} \label{def:measurable}
A contagion process is \textbf{threshold measurable} if we can correctly measure thresholds for all nodes in the contagion process according to Definition \ref{def:measured} for any $(G, U, H, \Delta)$. In this case, $C$ = $V$ for all $(G, U, H, \Delta)$.
\end{definition}

\noindent
Note that Definition \ref{def:measurable} requires a guarantee that all thresholds can be correctly measured for any graph, update ordering, threshold vector, and activation delay vector. Since we have phrased this definition as a requirement for all nodes and all $(G, U, H, \Delta)$, we can prove that Definition \ref{def:measurable} does not hold by providing a \emph{counterexample}.

A natural objection to this phrasing is: what if there are specific restrictions we may place on $(G, U, H, \Delta)$ that allow processes to be threshold measurable. We detail one such process below, and the complexity of this process suggests that threshold measurability is not common. Further, the counterexamples we provide are extremely simple graphs comprising three and four nodes (see Figure \ref{fig:tetradplot}).

\subsection{Which Processes are Threshold Measurable?}

\begin{theorem} \label{theorem:public}
No process where $(G, U, H, \Delta)$ is unrestricted is threshold measurable
\end{theorem}

\begin{proof}
Since we play the role of ``nature'' creating a counterexample, we have control over $(G, U, H, \Delta)$. Assume that $V = (i, j, k)$, $E = ((i, j), (j, k), (k, i))$, and $h_i = h_j = 0$, $h_k = 1$. Let $U = (\{k\}, \{i, j\}, \{k\})$ so that $k$ updates at time 1, $i$ and $j$ update at time 2, and $k$ updates again at time 3. Let $\Delta = (0, 0, 0)$, indicating no lags in public activation.

Then the contagion process plays out as follows: at time 1, $k$ checks and sees that it has exposure 0, which is less than its threshold of 1, and so $a_k = 0$. At time 2, $i$ and $j$ activate since they have threshold 0 and no activation lag. Then at time 3, $k$ checks and sees that $e_k = 2$ while $h_k = 1$, and so activates immediately. Since $k$'s two updates produce $e_k^1 = 0$ and $e_k^3 = 2$ while $a_k^1 = s_k^1 = 0$ and $a_k^3 = s_k^3 = 1$, Definition \ref{def:measured} is not satisfied and the process is not threshold measurable. In particular, all we know is that $k$'s threshold lies in the interval $(0, 2]$

\end{proof}

\noindent
This is our main result. When we have control over $(G, U, H, \Delta)$ to create our counterexample, it is trivial to create small graphs on which nodes are not correctly measured, which implies the process is not measurable. Since large contagion processes are in a sense composed of small contagion processes, our ability to find small structures that violate threshold measurability implies that we should \emph{never} expect a contagion process in the social world to be threshold measurable.

\begin{comment}
\begin{definition} \label{def:collision}
A \textbf{collision} occurs if, for some $i$ and some update times $t, t' \in U_i$, more than one neighbor of $i$ activates publicly.
\end{definition}

\noindent
It's clear that collisions cause incorrect measurement of thresholds. The reason measurability fails with no constraints on contagion processes is precisely because collisions occur. Collisions are in a sense inevitable when high degree nodes are present, although the probability of a collision occurring is particular to specific processes, and reliant on assumptions about node update times and graph topology.
\end{comment}

\begin{theorem} \label{theorem:fast}
There exists a $(U, \Delta)$ that ensures a contagion process where $S$ is observed is threshold measurable
\end{theorem}

\begin{proof}
It helps to return to our intuition in Section \ref{sec:intution}. For each node to be correctly measured, the contagion process must mimic an experiment in the sense that each node must update and record its status after each alter activation. Since we would like threshold measurability for arbitrary $G$ and $H$, this implies that each node must update after each activation. We can construct a $U$ and $\Delta$ that allow this.

Let $z$ be the set of satisfied unactivated nodes, where $s_i = 1$ and $a_i = 0$ for all $i \in z$. At each time $t = \{0, 2, 4, 6, ...\}$, have all unactivated nodes $V \setminus z$ update simultaneously. For each node $i \in V \setminus z$ whose threshold is satisfied, add $i$ to $z$ and assign $i$ a public activation delay $\delta_i = 2|z| - 1$. This means that at even times, all nodes update, and at odd times, a single node publicly activates. Then this defines a $U$ and $\Delta$.

To see that such a process is threshold measurable, consider any $i \in V$. By assumption, $i$ activates eventually. Since $i$ updates at every time $t = \{0, 2, 4, 6, ...\}$ and we know $S$ at each $t$, find $t^* = min(t) : s_i = 1$. By construction, exactly one node activated publicly at $t^* - 1$, which implies that $i$'s true threshold is $h_i = e_i^{t^*}$, $i$'s exposure at $t^*$.
\end{proof}

\noindent
Importantly, we require the ability to \emph{construct} $U$ and $\Delta$ as the process is unfolding. This type of centralized control does not exist in social networks, which are decentralized by definition. We note that there are likely other constructions of $U$ and $\Delta$ that satisfy the intuition in Section \ref{sec:intuition}. And, as we noted above, there may be other restrictions on $(G, U, H, \Delta)$ that allow threshold measurability.

\begin{theorem} \label{theorem:public}
No process where $G$ and $H$ are fixed and $S$ and $\Delta$ are hidden is threshold measurable
\end{theorem}

This theorem says that if we do not know private information for all user, and do not know node activation delays (or if node activation delays are 0), then the process is not threshold measurable.

\begin{proof}
Note that Theorem \ref{theorem:fast} relies on being able to record private threshold satisfaction status $s_i$ for every node. For that theorem, we devised a $(U, \Delta)$ that took any $(G, H)$ and ensured threshold measurability. For this proof, we provide a $(G, H)$ that, for any $(U, \Delta)$, fails to be threshold measurable when $S$ and $\Delta$ are hidden. Define an activation ordering $Q$, which records the times at which nodes publicly activate. Note that for $i$, $q_i = u_i^* + \delta_i$, where $u_i^* = \min(t) : e_i \ge h_i$. Since $i$ activates eventually by assumption, $u_i^*$ exists.

Now, we construct a $(G, H)$ for which any $Q$ produces collisions (see Figure \ref{fig:tetradplot}). Let $V = (i, j, k, l)$ and $E = ((i, j), (i, k), (j, k), (j, l), (k, l))$. Let $h_i = 0$ while $h_j = h_k = h_l = 1$.

Node $i$ must activate first. After it does, we have one of three cases:
\begin{enumerate} \label{theorem:impossible}
\item $q_j < q_k$: When $k$ activates, $k$ has 2 active neighbors, so a collision has happened
\item $q_j > q_k$: When $j$ activates, $j$ has 2 active neighbors, so a collision has happened
\item $q_k = q_j$: When $l$ activates, $l$ has 2 active neighbors, so a collision has happened
\end{enumerate}

\noindent
We have shown that there exists a $(G, H)$ that fails to be threshold measurable for any $(U, \Delta)$ when $S$ and $\Delta$ are hidden.

\end{proof}

\begin{figure}[h]
\label{fig:tetradplot}
\includegraphics[width=\textwidth]{tetradplot.png}
\caption{An example of one realization of $Q$, corresponding to case 3 from Theorem \ref{theorem:impossible}. Blue nodes are inactive, orange nodes are active. Squares represent correctly measured nodes, triangles represent incorrectly measured nodes.}
\end{figure}

\section{Biased Estimation of Social Influence}

\begin{comment}
Assume for simplicity: no activation delays, update ordering is not correlated with threshold

Then we know: E[x | y] is biased upward, since E[x | y = 1] is biased upward and E[x | y = 0] is not biased

We have 2 cases:
1) estimating a probability of adoption at each threshold
2) estimating a marginal effect, a beta coefficient, of the utility of adopting neighbors

Consider the CEF E[y | x], at each x, this will just give the probability that an individual is active in the sample

We can write beta as E^-1[x * x] E[x * y] = sum xy / sum xx

\end{comment}

Theorem \ref{theorem:public} implies that social contagion processes observed in the real world will suffer collisions (Definition \ref{def:collision}) and therefore some measured thresholds will be greater than true thresholds. Consider such a process where collisions have occurred, and further assume we have observed the entire process, so we may reason about a fully enumerated finite sample. Let $h_i$ be node $i$'s true threshold and $\hat{h}_i$ our measurement from observing a contagion process, obtained by taking $e_i$ at $i$'s first activation time. Since we know that for at least one $i$, $\hat{h}_i > h_i$, then $E[\hat{h}_i] > E[h_i]$.

For simplicity, we make three assumptions: (i) there are no activation delays ($\delta_i = 0$ for all $i$); (ii) node update orderings $U_i$ are uncorrelated with thresholds $h_i$ for all nodes $i$; (iii) the activation probability is monotonically increasing in $e_i$. The first assumption avoids more complicated modeling forms taking lags into account, while the second removes a potential selection bias problem that could complicate the analysis. The third simplifies analysis by assuming that the benefit to additional adopters is always positive, and allows us to use a simpler regression form for explanation.

To see the nature of bias only due to mis-measurement, consider a conditional expectation function, $E[y_i | E_i = e_i]$, which gives the probability of adoption at each exposure level. Imposing a parametric form on this conditional expectation will yield a model such as

\begin{equation} \label{eq:truemod}
y_i = \alpha + \beta e_i + \epsilon_i
\end{equation}

\noindent
which we can estimate using regression. $\beta$ represents the increase in adoption probability from one additional adopting neighbor. For our purposes, let's assume that Equation \ref{eq:truemod} is the true model generating the data. Within each cell given by $e_i$, we have $E[y_i | E_i = e_i]$. Rewrite $E[y_i | E_i = e_i] = \frac{\#(Y_i = 1 | E_i = e_i)}{\#(E_i = e_i)} = \frac{\#(\hat{H}_i = e_i)}{\#(E_i = e_i)}$, where $\hat{H}$ is the measured activation threshold for each node.

$\hat{H}$ is biased upwards by Theorem \ref{theorem:public}. This bias has the effect of taking $y = 1$ observations from low values of $e_i$ and shifting them to higher values of $e_i$. This crates an under-estimate in cells of $e_i$ where there is more ``out-migration'', and overestimates where this is more ``in-migration''.

To see this formally, note that our first two assumptions in this section ensure that we correctly sample unactivated nodes. Let $e_i^0$ represent an unactivated node with exposure $e_i$ and $e_i^1$ be an activated node with exposure $e_i$. Then $\#(E_i = e_i) = \#(E_i^0 = e_i^0) + \#(E_i^1 = e_i^1)$. A ``bias event'' that moves an observation to a higher value of $e_i$ subtracts 1 from the numerator and 1 from $\#(E_i^1 = e_i^1)$ in the denominator. Note that $\frac{x - 1}{c + x - 1} < \frac{x}{c + x}$ while $c, x \ge 1$. Since $\#(E_i^0 = e_i^0)$ stays fixed\footnote{Under the assumptions above, we can be sure that a node that updates but does not activate has not had its threshold met. Further, since we assume $U_i$ is uncorrelated with $h_i$, we obtain a random sample of the unactivated nodes.}, we conclude that when bias \emph{subtracts} active nodes from a cell, we underestimate the probability in that cell. A similar argument shows that, when bias \emph{adds} active nodes to that cell, we overestimate the probability.

The exact result of this shuffle in any particular instance is indeterminate when estimating conditional probabilities. There may be cells in the middle of the $E_i$ distribution that have little out-migration and much in-migration, creating an artificial spike in the estimated adoption probability. Alternately, very high values of $e_i$ may recieve all the in-migration, stretching out the range of $E_i$. Probability must be shifted to higher values of $e_i$, but little other than this general statement can be derived without additional specifics.

However, when we turn to a parametric model such as Equation \ref{eq:truemod}, it's easier to reason about the effects on estimating social influence. It's well known that when we mis-measure an independent variable, coefficients are biased towards zero \parencite{frost2000}. However, we obtain an upwardly biased measure of $e_i$ when $y_i = 1$, not a zero-mean mismeasurement. This will tend to mean that $y_i = 1$ values have higher values of $e_i$ than they would otherwise. Even if there is an even chance for nodes to be active at all values of $e_i$, the bias in measurement will tend to shift $e_i$ upward for $y_i = 1$ and flatten out $\hat{\beta}$ relative to the true $\beta$.

Two simple plots here display a simulation where individuals are assigned exposures between 1 and 9, and are activated with probability $0.1 e_i$, so probabilities of activation range from 10\% to 90\%, with $\beta = 0.1$ and $\alpha = 0$. We see that the upward bias in measuring the activated subset causes us to underestimate $\beta$.

<<PLOTS HERE>>

Finally, we emphasize that Model \ref{eq:truemod} and nonparametric probability models do not contain the concept of a threshold explicitly. Regression and probability models of adoption decisions are susceptible to bias due to Theorem \ref{theorem:public} due to the arguments laid out above. We should expect bias whenever we use observational data to model the effect of an additional neighbor adoption on ego behavior, simply because we use an upwardly biased measure of exposure for activated nodes.

\section{Network simulations}

\begin{comment}
TODO:
  make rmse at k plots (need naive at k, plus the baseline of using all)
    can split this up into a nice panel or something
  make regression bias plots above
  change error plots to a table (e.g. how negative is the error)


\end{comment}

The arguments offered above have the flavor of an impossibility proof. We should not expect, in the social world, to correctly measure all activation thresholds. However, without assumptions about threshold distributions, update frequencies, and graph generation processes, it is difficult to reason about the specific rates of the problems we have identified above. How often do we mis-measure thresholds? How large is the bias introduced by this mis-measurement? Succinctly: we mis-measure frequently and the bias is enormous.

To establish these results, we conduct simulations. <<Simulations have been used to establish well-accepted results about the social world, cite a bunch of stuff>> We choose two simulated graph topologies: Watts-Strogatz \parencite{} and power law with clustering \parencite{}. In addition, we use several empirical topologies from online social networks \parencite{}. We simplify from the very general treatment of contagion in section \ref{sec:measurability}: the processes studied here have no activation delays and no private information. In the language developed above, $\delta_i = 0$ for all $i$, and $S$ is hidden.

After establishing the severity of the problem, we suggest a parametric modeling approach to reduce the bias using the subset of nodes that are correctly measured. This reveals an intersting phenomenon: nodes that are correctly measured tend to be systematically different from the overall population. Specifically, correctly measured nodes tend to have negative error terms, since more nodes early in a contagion process are correctly measured. This implies that covariates (features) with high explanatory power are necessary to correctly model social contagion, since a high level of explained variance puts a limit on the bias that can be introduced by the error. It also suggests that further work needs to be done examining the particular nature of bias introduced by statistical modeling of processes in social networks.

\subsection{Simulation Details}

We conduct simulations on four graph topologies: random graph, Watts--Strogatz \parencite{Watts1998}, Barabási–-Albert \parencite{Barabasi1999}, and power law with clustering \parencite{Holme2002}. Graphs have 1000 nodes, with mean degree $\bar{d} = \{12, 16, 20\}$. We run simulations 100 times per graph parameterization. We present results only from Watts--Strogatz and power law with clustering graphs here, as results from the other topologies are not markedly different. We detail the simulation algorithm in Appendix <<>>.

\subsection{Thresholds from Covariates}

\cite{Granovetter1978} generates thresholds by simply drawing from a uniform or Gaussian distribution, while \cite{Watts2002,Kempe2003} use a uniform distribution. In empirical research, however, we often employ actor-level characteristics to explain outcomes. If we treat a node's threshold as the outcome to be explained, we can construct a model of ego's threshold as a function of ego-level covariates, including ego-network characteristics (e.g. degree) and ego's network-level characteristics (e.g. ego's betweenness).

To our knowledge, thresholds have not been treated as an outcome variable, and have traditionally been used as an explanatory variable. In addition to the theoretical usefulness of explaining thresholds, we we need to develop a model with thresholds as the outcome in order to predict thresholds for the incorrectly measured nodes. Recasting thresholds in a regression framework makes Granovetter's model a special case of ours, where we suppress the importance of actor-level covariates in favor of studying other theoretical questions.

For our simulations, we generate thresholds from a simple parametric model. $h_i$ is node $i$'s threshold. Define $x_i \sim \mathcal{N}(0, 1)$ as an explanatory variable. Let $\epsilon_i \sim \mathcal{N}(0, \sigma)$ be the unmeasured idiosyncratic error of $i$. We treat $\sigma$ as a parameter to explore and vary it from ${0.5, 0.8, 1.0, 1.5, 2.0}$. Then we have the \emph{threshold equation}

\begin{equation} \label{eq:thresh}
h_i = \beta_0 + \beta_1 x_i + \epsilon_i
\end{equation}

\noindent
For simulation purposes, assume the parameters of this model to be

\begin{equation} \label{eq:sim_thresh}
h_i = 5 + 3 x_i + \epsilon_i
\end{equation}

\noindent
Treating the error standard deviation $\sigma$ as a parameter allows varying the maximum explained variance in the model. A high value of $\sigma$ means that even a perfect model will have modest explanatory power, represented by a low $R^2$.

\subsection{Which Thresholds Are Correctly Measured?}

We choose one run of the simulation with a power law with clustering graph with mean degree 20 for exposition. We see in Figure \ref{fig:obs_vs_not} that measured thresholds tend to be lower-valued thresholds. As shown in Figure \ref{fig:obs_rate}, the correct measurement rate for the simulations we study ranges between 6\% and 19\%.

\begin{figure}[h]
\label{fig:obs_vs_not}
\includegraphics[width=\textwidth]{obs_vs_not.png}
\caption{Correctly measured thresholds for one run of the power law with clustering graph with mean degree 20. Correctly measured thresholds are in purple, while all measured thresholds are in red. For instance, if at a given threshold value, the purple bar reaches 40\% of the height of the red bar, it means that we measure 40\% of the thresholds at that value correctly.}
\end{figure}

\begin{figure}[h]
\label{fig:obs_rate}
\includegraphics[width=\textwidth]{observations.png}
\caption{Number of correctly measured thresholds by graph type and mean degree. Graphs have 1000 nodes. Each bar is averaged over the 5 different $\sigma$ values employed for the error term, comprising 5 different simulations with 100 replications each.}
\end{figure}

\subsection{Measurement Bias}

Only a small fraction of thresholds are correctly measured. Threshold intervals with size greater than 1 prevent us from being certain where an individual's threshold lies. The exposure-at-activation-time rule uses the maximum of the threshold interval as an individual's threshold, which always produces upward bias in measuring thresholds.

The amount of upward bias is a relevant question, however. In Figures \ref{fig:measured1} and \ref{fig:measured2} we plot the exposure-at-activation-time measurement against the true threshold. At all true threshold levels, upward measurement bias is substantial. In two particularly extreme cases, this simulation run results in a node of threshold 6 being measured with threshold 43, and a node with threshold 13 being measured with threshold 46. These represent high degree nodes that go long periods of time between updates.

This example is not anomolous: such outliers occur in every simulation we have examined visually. Without incorporating information on node update behavior and applying our measurement condition, any node observed with a high exposure at activation can be rationalized as a low-threshold node with a long update interval. In Figure \ref{fig:measured2} we replot Figure \ref{fig:measured1} with axes to scale, in order to give a clear visual indication of the level of mis-measurement induced by employing the exposure-at-activation-time rule.

\begin{figure}[h]
\label{fig:measured1}
\includegraphics[width=\textwidth]{measured1.png}
\caption{Plot of the thresholds versus measured thresholds. As we go across the $x$-axis, we see that at each true threshold value, measured thresholds are above the $x = y$ line, except for cases identified by our correct measurement condition. Note the different scales in the axes.}
\end{figure}

\subsection{Selection Into Correct Measurement}

We use the correctly measured subset of nodes to estimate the relationship between $Y$ and $X$. In graphs with 1000 nodes, this means using between 50-200 observations to estimate the model. If selection into correct measurement were random, then we would expect $\hat{\beta}$ to be unbiased, but with more variance due the reduction in sample size.

Figure \ref{fig:model_comparison} demonstrates the result of using OLS on a representative simulation run. The slope of the line generated from the correctly measured subset slightly understates the relationship between $X$ and $Y$. Using replications across our parameter space, we find that using the correctly measured subset to estimate $\beta$ does not recover the true relationship $\beta_1$ between $X$ and $Y$\footnote{This is not due to left-censoring. Tobit models are also biased.}.

\begin{figure}[h]
\label{fig:model_comparison}
\includegraphics[width=\textwidth]{model_comparison.png}
\caption{A comparison of OLS estimates for the relationship between $x$ and $y$ using the correctly measured subset and the true relationship in the data.}
\end{figure}

Biased parameters imply selection on the error term. Figure \ref{fig:error_bias} presents the error term in the correctly measured subset as a function of model parameters. Note that, on average, the error term is negative for all parameter values, while the true error is mean 0 by construction. This demonstrates the presence of selection bias. Returning to Figure \ref{fig:obs_vs_not}, we are more likely to correctly measure lower thresholds, meaning that having a negative error term makes it more likely that we correctly measure a node's threshold.

\begin{figure}[h]
\label{fig:selection_bias}
\includegraphics[width=\textwidth]{selection_bias.png}
\caption{The true values from Equation \ref{eq:sim_thresh} are a constant of 5 and a beta coefficient of 3. We see here that, as we increase the unexplained variance in the model in the form of error standard deviation, we create more variance in our predictions and, in most cases, introduce more bias as well. Colors correspond to graph type, with shades of blue representing power law graphs with clustering, and shades of orange representing Watts-Strogatz graphs.}
\end{figure}

The standard response to selection bias is to model it as a function of observables using a Heckman procedure \cite{}. Since we know the true model (Equation \ref{eq:sim_thresh}), the only other variables that we can include are network measures. We hypothesized that nodes in certain network positions would be more likely to be selected into correct measurement. For instance, perhaps lower degree nodes would be more likely to be correctly measured. In our simulations, using ego's degree, closeness, betweenness, and eigenvector centrality in the first stage of a Heckit procedure did not reduce selection bias. We leave further investigation of network-level factors leading to selection into correct measurement for future research.

Since we are unable to model the selection bias, we have \emph{selection on the error}, which results in the correctly measured subset having a \emph{systematically different} relationship between $X$ and $Y$ in the correctly measured subset than the population. In other words, $\hat{\beta} \neq \beta$.

\subsection{The Effects of Selection Bias}

There are two reasons to estimate Equation \ref{eq:sim_thresh}: to recover an unbiased $\hat{\beta}$ to explain causes of individual thresholds; or to use the estimated model to predict thresholds for the incorrectly measured nodes in order to recover the threshold distribution. This is an \emph{explanation} versus \emph{prediction} problem, as discussed in \cite{Kleinberg2015}.

\begin{figure}[h]
\label{fig:epsilon}
\includegraphics[width=\textwidth]{epsilon.png}
\caption{The value of epsilon in the correctly measured subset for values of the error standard deviation.}
\end{figure}

Figure \ref{fig:epislon} displays the average value of the error term in the correctly measured subset. As we increase the unexplained variance in the true model, selection on the error becomes worse. We see in Figure \ref{fig:selection_bias} the level of bias in $\hat{\beta}$ for increasing $\sigma$. When $X$ explains much of the variance in $Y$, $\hat{\beta}$ is close to $\beta$, although still biased. When $\sigma$ is larger, nodes with larger negative error terms are selected into correct measurement, which increases the bias on $\hat{\beta}$. This indicates that using our methodology to explain factors that contribute to thresholds must be done carefully, and researchers must have strong theoretical reasons to believe that the correct variables are included in the model. We note that the $R^2$ of the regression on the correctly measured subset is \emph{not} the same as the $R^2$ on the true model in the population, and an argument that good predictors are included in the model is primarily theoretical.

The increasing level of bias on $\hat{\beta}$ as $\sigma$ increases creates specific conditions for which $\hat{\beta}$ may be interpreted for \emph{explanation}. However, we find that at any level of $\sigma$, our method performs well when using $X$ for \emph{prediction} in order to recover the threshold distribution $Y$ for all nodes. In this context, bias in $\hat{\beta}$ is far less problematic. Figures \ref{fig:rmse_at_k_sd} and \ref{fig:rmse_at_k_graph} demonstrates the RMSE for predicting $Y$ for all nodes in the graph, using only the correctly measured subset. We use the RMSE of the exposure-at-activation-time rule as a baseline\footnote{This compares $e_{i,t}$ for the first $t$ at which $i$ is active to $h_i$, the true threshold of $i$.}.

We see that, even as we increase $\sigma$, we do not substantially increase the prediction error. If we treat the total RMSE as composed of \emph{bias} and \emph{variance}, we see that the vast majority of RMSE at high levels of $\sigma$ is due to variance. This implies that, even if coefficients are biased, simple regression methods provide good predictions of $Y$, and allow recovering the true threshold distribution with high accuracy.

\subsection{Prediction Error Using $k$ Correct Measurements}

Prediction performance is good when using the entire correctly measured subset, but in many empirical applications we wish to predict future diffusion performance from its initial behavior \parencite{Cheng2014a}. We address the ability to predict node thresholds using only the first $k$ correctly measured nodes.

\begin{figure}[h]
\label{fig:rmse_at_k_sd}
\includegraphics[width=\textwidth]{rmse_at_k.png}
\caption{We see the RMSE using the first $k$ correctly measured nodes to predict thresholds for the whole graph. Here we break down RMSE by error SD, and see that higher error SD corresponds to higher RMSE. This does not disentangle bias and variance.}
\end{figure}

\begin{figure}[h]
\label{fig:rmse_at_k_graph}
\includegraphics[width=\textwidth]{rmse_at_k_graph.png}
\caption{We see the RMSE using the first $k$ correctly measured nodes to predict thresholds for the whole graph. Here we break down RMSE by graph type, and see that both graphs have about the same prediction error when $k > 100$ (or 10\%). This does not disentangle bias and variance.}
\end{figure}

\begin{figure}[h]
\label{fig:bias_vs_variance}
\includegraphics[width=\textwidth]{bias_vs_variance.png}
\caption{This figure plots the ideal RMSE at a given error standard deviation versus the RMSE from the model estimated with the correctly measured subset. The gap between the baseline (dark blue line) the cyan and red lines represents the RMSE due to bias. We see that RMSE due to bias does not increase dramatically as the unexplained variance increases.}
\end{figure}

\section{Conclusion}

In this paper, we have identified the conditions under which node thresholds are correctly measured. By analogy with a laboratory experiment, we have shown that the private threshold satisfaction state of nodes must be measured after each alter adoption for contagion processes to be threshold measurable in the social world. Since this condition is strict, in virtually all empirical and simulation cases, some thresholds will be incorrectly measured.

Despite this incorrect measurement, we show that employing a simple regression technique provides low-bias parameter estimates when observables explain a large fraction of the variance in thresholds. Even when explained variance is low, parameter bias adds relatively little prediction error beyond the prediction error from variance. We view this result as encouraging for work that wishes to recover threshold distributions in empirical settings. However, when a model of thresholds is interpreted as explanatory, researchers must carefully craft theoretical arguments that the incorporated variables have both explanatory power and causal relevance.

Importantly, our results draw attention to the perils of statistical modeling in networked contagion processes. Models of contagion that do not explicitly employ the concept of a threshold are susceptible to bias from the results we present here, and only full control over ego perceptions avoids this bias. In studies that model the utility of adoption decision based on observational peer behavior \parencite{econ stuff, christakis}, we should expect estimates to be biased due to Theorem \ref{theorem:public}. This is a general result that the modeling literature has to address.

Our positive reuslt about the usefulness of regression for modeling threshold distributions suggest that we may categorize a contagion processes by its \emph{threshold distribution}. This has been theoretically relevant since \cite{Granovetter1978}, but has not been operationalized empirically to our knowledge. In contrast to structural categorizations of diffusion \parencite{Goel2012}, a threshold distribution categorization of diffusion facilitates new explanations for the success or failures of diffusion. We look forward to future work contrasting contagion processes on the basis of their threshold distributions.

\blankpage
\blankpage
\blankpage
\blankpage

\section{Appendix}

For each simulation trial, we use the following simulation algorithm:
\begin{enumerate}
\item Generate a random asynchronous update order for all nodes $C$, which has one node per interval.
\item For each node in $C$:
	\begin{enumerate}
	\item If the node is active, do nothing
    \item If the node is inactive:
    	\begin{enumerate}
        \item If the node's threshold is satisfied: activate it
        \item If the node's threshold is not satisfied: do not activate, and record the number of active neighbors
        \end{enumerate}
	\end{enumerate}
\item If not all nodes in the graph are active and at least one node was activated in the last pass through $C$, generate a new $C$ and repeat the process
\item Stop if all nodes have been iterated through without any activations
\end{enumerate}

\noindent
This algorithm allows the social contagion to diffuse maximally, since if all nodes are checked at random and none update, no alternate update ordering will change the outcome. We record the number of active neighbors at each node update time, even if the node does not activate. This allows us to construct a threshold interval from the data as found in Definition \ref{def:measured}. If a node has a threshold interval of size 1 or had 0 neighbors active at activation time, it is correctly measured. Otherwise, it is incorrectly measured.


\printbibliography
\end{document}
